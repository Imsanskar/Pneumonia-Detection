{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "from utils.cnn import Classifier\n",
    "from utils import train, infer\n",
    "from utils.evaulation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomAffine(translate=(0.05,0.05), degrees=0),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225] ,inplace=True)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225] ,inplace=True)\n",
    "])\n",
    "subset_ratio = 0.2\n",
    "orig_dataset = ImageFolder(root='../dataset/chest_xray/train/', transform = train_transform)\n",
    "n = len(orig_dataset)  # total number of examples\n",
    "print(f\"Total Dataset size: {n}\")\n",
    "\n",
    "indices = list(range(n))\n",
    "# randomly shuffle the indices\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# calculate the split index for the subset\n",
    "split = int(np.floor(subset_ratio * n))\n",
    "\n",
    "val_sampler = SubsetRandomSampler(indices[:split])\n",
    "train_sampler = SubsetRandomSampler(indices[split:])\n",
    "test_dataset = ImageFolder(root='../dataset/chest_xray/test/', transform = test_transform)\n",
    "\n",
    "train_dataloader = DataLoader(orig_dataset, batch_size = 64, sampler=train_sampler)\n",
    "val_dataloader = DataLoader(orig_dataset, batch_size = 16, sampler=val_sampler)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle = True, batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "# optim = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 0.0001\n",
    "optim = torch.optim.SGD(model.parameters(), lr = lr, momentum=0.9, weight_decay=1e-3)\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Losses, Val_f1, Val_accuracy = train(model, optim, loss_fn, train_dataloader, epochs = 10, early_stop_threshold=5, model_filename=\"./models/cnn_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "print(f\"Accuracy: {calculate_accuracy(model, test_dataloader)}\") \n",
    "y_pred = []\n",
    "y_true = []\n",
    "for images,labels in test_dataloader:\n",
    "    for i in range(len(labels)):\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        img = images[i].view(1, 3, 224, 224)\n",
    "        with torch.no_grad():\n",
    "            logps = model(img)\n",
    "\n",
    "\n",
    "        ps = torch.exp(logps)\n",
    "        probab = list(ps.cpu()[0])\n",
    "        pred_label = probab.index(max(probab))\n",
    "        y_pred.append(pred_label)\n",
    "        y_true.append(labels.cpu()[i])\n",
    "f1_score, precision, recall = f1_loss(torch.tensor(y_true), torch.tensor(y_pred))\n",
    "f1_score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.xticks(range(len(Losses)))\n",
    "plt.plot(Losses)\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(Val_accuracy)\n",
    "\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Validation F1 Score\")\n",
    "plt.xticks(range(len(Losses)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/plot_conv_net.pdf\")\n",
    "plt.show()\n",
    "print(Losses, Val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "class_names = ['Normal', 'Pneumonia']\n",
    "df_cm = pd.DataFrame(cf_matrix, index = class_names, columns = class_names)\n",
    "sb.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "plt.savefig(\"conv_net_confusion_matrix.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Activation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = enumerate(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (example_data, target) = data.__next__()\n",
    "feature_map = model.get_feature_map(example_data.to(device))\n",
    "pred = infer(model, example_data)\n",
    "weights = model.fc[0].weight.data\n",
    "cams = return_CAM(F.avg_pool2d(feature_map, 27), weights, pred)\n",
    "heat_map = cv2.applyColorMap(cv2.resize(cams[0],(224, 224)), cv2.COLORMAP_JET)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(0.5*(example_data)[0].permute(1, 2, 0) + 0.5 * (heat_map / 255))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(heat_map)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow((example_data)[0].permute(1, 2, 0))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "print(pred[0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "830d689a0fb977be779658ea24d172cac3a688ad2555a7f0a0274256a1ea9bef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
